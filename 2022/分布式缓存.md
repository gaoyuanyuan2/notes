# 分布式缓存

## 缓存的几种淘汰策略

* 先进先出算法(FIFO) 
 * 如果一个数据最先进入缓存，则应该最早淘汰掉。
* 最不经常使用(LRU)
 * 判断数据最近使用的时间，时间最远的数据优先被淘汰。
* 最近最少用(LFU)
 * 在一段时间内，数据被使用的次数最少，优先被淘汰。

## 前提:我们的应用扛不住用户并发量的时候

* 将数据库部分数据加入到缓存
 * 把一些经常访问的数据放到缓存当中

* 列表排序分页等场景

* 计数器

* 详情内容数据缓存

* 分布式session

* 热点排名

* 发布订阅

* 分布式锁
 * 数据库
 * ZooKeeper
 * Consul
 * etcd
 * Redis

##  常见的客户端缓存包括以下几种:

* 页面缓存
 * 页面自身对某 些元素或全部元素进行缓存。
 * 服务端将静态页面或者动态页面进行缓存，然后给客户端使用。
* 浏览器缓存
* App缓存
 * Android:
   * 轻量级缓存框架: ASimpleCache
   * 可以缓存: JSon、BitMap、序列化的Java对象和二进制数据等。
 * iOS:
   * 常用缓存框架: SDWeblmage、NsCache等等。

## 服务端缓存

### 数据库缓存

* 使用Query Cache就是一把双刃剑:
  * 如果数据库修改较少的情况，使用Query Cache能够大幅提高查询效率。
  * 如果数据库频繁修改所的情况，使用Query Cache将会成为系统的负担，查询效率反而会降低。

* 平台级缓存就是带有缓存功能的专用库，或者具有缓存特性的框架。
  * Ehcache
    * 轻量快速、 良性伸缩、标准支持、扩展性强、数据持久、缓存监听、分布式缓存
  * Jboss Cache
    * 支持树状结构、支持集群、支持事务的缓存框架、缓存加载器、驱逐策略、缓存钝化、并发
  * OSCache
  * Guava Cache
    * Guava是Google提供的一套Java工具包，而Guava Cache是完善的本地缓存。
    
### 平台级缓存

为什么不用Map来作为本地缓存库?

1.内存管理
2.缓存过期策略
3.容量规划
4.Map是否是线程安全的
5.持久化
6.多实例数据同步及-致性

特点:
* 基于应用程序的缓存库
* 具有一定的分布式能力
* 数据不能保证强一致性
* 无法保证高可用


### 应用级缓存

* Redis 和Memcached 比较
|比较项|Memcached|Redis|
|:--:|:--:|:--:|
|数据结构|只支持简单的key/value结构|String、Hash、List、 Set、SortedSet|
|持久化|不支持|支持|
|容量大小|内存，数据存储不宜过多|内存|
|读写性能|很高|很高|
|线程模型|多线程|Redis6.0以前是单线程|


#### CDN缓存

Content Delivery Network ( 内容分发网络)

* 使用CDN有哪些优点:
  * 本地Cache加速
  * 实现跨运营商的网络加速
  * 远程加速
  * 带宽优化
  * 集群抗攻击

## JSR107

Jcache规范定义了-种对Java对象临时在内存中进行缓存的方法，包括对象的创建、共享访问、假脱机(spooling) 、失效、各JVM的一致性等,可被用于缓存最经常访问的数据。

## 客户端缓存选型：Ehcache、GuavaCache、SpringCache的区别与技术选型

* Ehcache的特点:
  * 多级缓存策略
  * 缓存的数据在内存和磁盘当中
  * 缓存数据在虚拟机重启的过程中写入磁盘
  * 可以通过RM|或接口的方式实现分布式缓存
  * 允许注册事件来侦听缓存

* Guava Cache的特点:
  * 相对于 CurrentHashMap,限制内存的使用，会自动回收元素。

* Spring Cache的特点:
  * 通过少量的配置就可以使得既有代码支持缓存
  * 不用安装和部署额外第三方组件就可以使用缓存
  * 支持Spring Express Language
  * 支持Aspect
  * 支持自定义key，具有相当的灵活性和扩展性
  
|能否持久化|是否有集群方案体积|是否庞大|是否有辅助功能|是否轻量|
|:--:|:--:|:--:|:--:|:--:|
|Ehcache|是|是|相对大|有|否|
|Guava Cache|否|否|否|否|是|
|Spring Cache|否|否|否|否|是|

### Guava Cache

#### 为什么使用本地缓存?
* 相对于I/0操作:速度快,效率高。
* 相对于Redis: Redis 虽然优秀，但受限于网卡等原因，远水救不了近火。

#### Guava Cache的使用场景:
* 愿意消耗一些内存空间来提升速度
* 预料到某些键会被多次查询
* 缓存中存放的数据总量不会超出内存容量


#### 缓存的回收三种方式:

* 按容量回收
* 定时回收
* 基于引用回收

## 服务端缓存选型：Redis、Memcached的区别与技术选型

|对比项|基于内存|数据结构|虚拟内存|过期策略数据持久|灾难恢复性能|
|:--:|:--:|:--:|:--:|:--:|
|Redis|是的|List,set等多种|物理内存用完，可以将不用的数据交换到磁盘|有|有|有|高|
|Memcached|是的|k/v|无|有|无|无|高|

Memcached只适合基于内存的缓存框架对数据持久和灾难恢复所提供能力是欠缺的

采用了Redis缓存框架作为集中式缓存


## Redis

Redis与Reactor 模式两者有什么关系

Redis的工作模式:
1.多个client连接server
2.发送命令给server
3. server返回结 果给client

Redis是使用单进程，还是多进程?
Redis是使用单线程，还是多线程来处理客户端的请求呢?

影响Redis的性能的因素不是因为CPU的因素，而是因为网络10和内存是影响它们性能的最大因素

Redis之所以使用单进程单线程，为了在一定程度上减少线程的上下文切换

### I/O多路复用模式Reactor

Redis基于Reactor模式开发了自己的文件事件分派器。文件事件处理器使用I/O多路复用技术，同时监听多个套接字，并为套接字关联不同的事件处理函数。当套接字的可读或者可写事件触发时，就会调用相应的事件处理函数。


### 单机Redis会面临哪些问题?

1. 机器故障
2.容量瓶颈
3. QPS瓶颈

### 主从复制的作用:

1.提供数据副本
2.扩展读性能,也就是实现读写分离

### Redis主从复制的要点:

* 一个master 可以有多个slave 
* 一个slave只能有一个master
* 数据流是单向的，master到slave

* Redis主从复制.
  * 当一份数据落在了多个不同节点上,如何保证节点间数据的一致性将是关键点。
  * Redis采用主备复制的方式来保证一致性。
  
### 为什么要进行分片?

1.不用被局限在单服务器的内存容量
2.允许多服务器进行可扩展、可伸缩，可以利用多服务的多核能力

### 分片的一些常见问题:

1.不能直接对映射到多个实例的数据进行交集操作
2.跨实例不能进行事务
3.采用分片机制后，数据备份将变的复杂
4.添加和删除容量也变的复杂一些


* 分片的手段:
  * Redis集群支持
  * Twemproxy代理
  * 支持-致性哈希的客户端

### Redis为什么会使用单线程模型?

1.使用单线程模型能带来更好的可维护性,方便开发和调试
2.使用单线程模型也能并发的处理客户端的请求

* 采用1/0 多路复用机制来并发处理多个客户端连接请求
* 优点:
  * 节省开销
  * 减少连接
  * 减少服务器的成本.

3. Redis 服务中运行的绝大多数操作的性能瓶颈都不是CPU

### Redis为什么单线程还这么快?

1.纯内存操作，操作的时间复杂度是O(1)
2.单线程操作，避免了频繁的上下文切换
3. I/O多路复用机制

使用单线程的缺点:
无法发挥CPU多核性能

### Redis6.0多线程模型解读

* 这一版本增加了哪些功能:
  * 1.重新设计了客户端缓存
  * 2.如 果用于复制的RDB文件不再有用，它将被立刻删除
  * 3.ACL方面做的更好
  * 4.改进了复制协议PSYNC2
  * 5.带有超时的Redis命令
  * 6.RDB文件加载 速度更快
  * 7.新增 新的命令STRALGO

* 使用多线程的优点:
  * 可以充分利用服务器CPU资源，目前主线程只能利用一核
  * 多线程任务可以分摊Redis同步I/O读写负荷

* Redis的I/O事件和时间事件融入在一起实现了I/O同步非阻塞
* 但I/O的数据读取依然是阻塞的，这将会成为Redis可能的性能瓶颈之一。
* 当数据量特别大的时候， 因为是单线程处理 所以耗时也就很长。
* Redis 6.0引入多线程机制对此问题进行了优化。

* 思路:
  * 将主线程的I/O读写任务拆分出来给一组独立的线程执行,使得多个socket的读写可以并行化，但主线程的命令依旧是串行执行。

## Redis 6.0多线程模型有以下特点:

* I/O线程要么同时在读socket,要么同时在写，不会同时读或写
* I/O线程只负责读写socket解析命令，不负责命令处理
* I/O线程数可自行配置

## Memcached

### Memcached的多线程模型

* Memcached 是个单进程多线程的程序，其底层使用libevent来管理事件，无论是主线程还是worker线程，都是通过libevent异步事件模型来管理事件。
* Memcached是个Master/Worker的线程模型。

Memcached中有以下几类线程:
* 主线程
* 工作者线程
* 维护线程

* Memcached工作流程:
  * 1. 主线程接受到Memcached客户端的请求。
  * 2. 主线程通过 round robin找到一个工作线程。
  * 3. 主线程将创建的连接push到工作线程的连接队列中，然后唤醒这个工作线程。
  * 4. 工作线程被唤醒后,从自己的线程队列中取出一个连接。
  * 5. 解析请求、对hash表进行相应的操作，写入返回。


### Memcached 服务之间不互相通信，那么是如何来实现的分布式呢?

* Memcached的分布式实现主要依赖客户端的实现
* 存取数据二步:
  * 1.选择Memcached服务器
  * 2.存取数据

常用的算法有两种:余数计算分散法和一致性Hash算法

### 优化一致性hash算法

* 般的一致性hash算法最大限度的抑制了键的重新分配，并且有的实现方式还采用了虚拟节点的思想。
* 服务器的映射地点的分布非常的不均匀，导致数据访问倾斜，大量的key被映射到同一台服务器上。
  * 虚拟节点:每台机器计算出多个hash值，每个值对应环上的一个节点位置。
  * key的映射方式不变,就多了层从虚拟节点到再映射到物理机的过程。
* 优化后:
  *在物理机很少的情况下，只要虚拟节点足够多，也能使的key分布相对均匀，提升了算法的平衡性。


### 问题

项目需要支撑500QPS,采用微服务架构，项目读多写少，每次在读取项目的时候,都需要先读取最新银行配置相关信息，如果银行配置相信信息更新，能够及时感知。

数据库读写分离
Redis 配置信息
一般情况下500QPS需要1~2台这样的一个配置的服务实例就够了

## 缓存穿透：发⽣场景和常⻅的破解招数

发生缓存穿透的场景

小张要查询银行配置信息，因为银行配置信息访问量都比较大，所以缓存在Redis中，可是小张在查询缓存的时候输错了银行编码,缓存中没有查到，而数据库中也没有相应的银行配置信息，而小张又不断发起重新查询。

* 方案一
  * 缓存设置null
* 方案二
  * 校验前置
  * 空值防范
  * 过载防护
* 方案三
  * 布隆过滤器
    * 删除数据比较难
    * 有一定的误识别率

## 缓存雪崩：发生场景和常见的破解招数

### 场景一

双十一抢购，一波商品时间比较集中的放入了缓存。假设缓存一个小时,那么到了凌晨一点钟的时候,这批商品的缓存就都过期了,而对这批商品的访问查询,都落到了数据库上,对于数据库而言，就会产生周期性的压力波峰。

一个是将缓存失效时间分散开,比如我们可以在原有的失效时间基础上,去增加一个随机值，比如1 ~ 5分钟随机，这样每一个缓存的过期时间的重复率就会降低，也就很难引发集体失效的事件了。

缓存不过期

### 场景二

一个key非常热点，在不停的扛着大并发，大并发集中对这-一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库,就像在一-个屏障上凿开了- -个洞。

热点key进行了哈希打散


## 缓存一致性（一）：多级缓存与数据库之间的⼀致性怎么保证

读的时候，先读缓存，缓存没有的话，就读数据库,然后取出数据后放入缓存，同时返回响应。更新的时候，先删除缓存，然后更新数据库。


1：通过Redis的过期时间来更新缓存，MySQL数据库更新不会触发Redis更新，只有当Redis的key过期后才会重新加载。
这种方案的缺点:据不一致的时间会较长，也会产生一 定的脏数据。完全依赖过期时间，时间太短容易缓存频繁失效，太长容易有长时间更新延迟。

2：在方案一的基础. 上扩展,让key的过期时间兜底,在更新MySQL的同时更新Redis。
这种方案的缺点:如果更新Mysql成功，更新Redis失败,就成了方案一。

3：在方案二的基础上,对Redis更新进行优化，增加消息队列，将Redis的更新操作交给MQ由消息队列来保证可靠性,异步更新Redis。
这种方案的缺点:解决不了时序的问题，如果多个业务实例对同一条数据进行更新，数据的先后顺序可能会乱。引入MQ,增加MQ的维护成本。

4：将MySQL更新和Redis更新放到一个事务中操作，这样就可以达到一致性。
这种方案的缺点:MySQL或Redis任何-个环节出现问题，都会造成数据回滚或撤消。如果网络出现超时，不仅可能会造成数据回滚或撤消,还会引起并发问题。

5：通过订阅Binlog来更新Redis,把我们搭建的消费服务,作为MySQL的一个slave,订阅Binlog,解析出更新内容，再更新到Redis。
这种方案的缺点:要单独搭建一个同步服务,并且引入Binlog同步机制，成本较大。

## 缓存一致性（二）：Ehcache和Redis如何搭配来实现缓存的最终一致性

对于一些缓存读取很高，更新频率很低的这种场景，可以使用本地缓存来进行。

更新频率搞用集中式缓存Redis

* 本地缓存和集中式缓存数据更新的策略
 * 广播更新策略
 * 定时更新策略
 
### 多级缓存使用注意点:

* 本地缓存必须设置超时时间，必须定时更更新本地缓存，防止因各种原因导致的本地缓存和Redis缓存不一致, 保证缓存的一致性。
* 对于并发量不大的场景, Redis缓存可以不用设置永久缓存，防止因更新失败导致的缓存不一致,以及僵尸类型的key占用服务器内存。
* 项目启动时要清空本地与服务器同步的缓存区域，以保证缓存的一致性。

## MyBatis

在分布式环境中也是不建议开启二级缓存的，因为缓存是保存到本地的，这样也会导致产生脏数据。


## 分布式锁

### 常见问题

* Redis主从复制一致性问题
* 如果setnx是成功的，但是expire设置失败，那么后面如果出现了释放锁失败的问题，那么这个锁永远也不会被得到，业务将被锁死?
  * 解决的办法:使用set的命令，同时设置锁和过期时间
* 锁过期了，业务还没执行完
  * 锁的续约机制
  
## 分布式Session

* 主流的分布式Session有两种方案
  * Session复制
  * Session集中式存储


## 配置中心



Apollo (阿波罗)是携程框架部门门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性,适用于微服务配置管理场景。

QConf是一个分布式配置管理工具。用来替代传统的配置文件，使得配置信息和程序代码分离，同时配置变化能够实时同步到客户端，而且保证用户高效读取配置，这使的工程师从琐碎的配置修改、代码提交、配置、上线流程中解放出来，极大地简化了配置管理工作。

Disconf专注于各种「分布式系统配置管理」的「通用组件」和「通用平台」,提供统- -的「配置管理服务」

Spring Cloud Config为分布式系统中的外部配置提供服务器和客户端支持。


## 秒杀

扣减库存有几种方式:

下单减库存
付款减库存
预扣库存

Redis本来就是单线程的，所以可以考虑把"检查库存-扣减库存-返回结果"的动作写成lua脚本去调用，一个调用就能原子化地操作库存了。

利用SQL事务


## 支付案例：基于Redis实现延时队列

* 在业务发展过程中，会出现一些需要延时处理的场景，比如:
  * 订单下单之后超过30分钟用户未支付，需要取消订单。
  * 订单一些评论，如果48小时用户未对商家评论,系统会自动产生一条默认评论。
  * 点我达订单下单后，超过一定时间订单未派出，需要超时取消订单等。。。

处理这类需求，比较直接简单的方式就是定时任务轮训扫表。这种处理方式在数据量不大的场景下是完全没问题，但是当数据量大的时候高频的轮训数据库就会比较的耗资源，导致数据库的慢查或者查询超时。所以在处理这类需求时候，采用了延时队列来完成。


### 几种目前已有的延时队列:

Java 中java.util.concurrent.DelayQueue
优点: jDK自身实现，使用方便,量小适用
缺点:队列消息处于jvm内存，不支持分布式运行和消息持久化

RocketMq延时队列
优点:消息持久化,分布式
缺点:不支持任意时间精度,只支持特定level的延时消息

RabbitMq延时队列(TTL+DLX实现)
优点:消息持久化,分布式
缺点:延时相同的消息必须扔在同一个队列

如果我们要自己实现一个延时队列需要考虑哪些点:
* 消息存储
* 过期延时消息实时获取
* 高可用性

实现思路:
* 将整个Redis当做消息池，以k形式存储消息, key为id, value为具体的消息body;
* 使用ZSET做优先队列，按照score维持优先级(用当前时间+需要延时的时间作为score) ;
* 轮询ZSET,拿出score比当前时间戳大的数据(已过期的) ;
* 根据id拿到消息池的具体消息进行消费;
* 消费成功，删除改队列和消息;
* 消费失败，让该消息重新回到队列。

## 在高并发场景下如何使用缓存来保存配置数据？

乐观锁CAS方案
库存增加版本字段version, 在更新库存时比较版本号，例如:
update amount_table set version = old_version + 1 ,stock = stock - 1 where version = query_version and id= XXX
只有版本号没有变化，才能更新库存成功,如果版本号发生变化，则更新库存失败并进行重试。

帐户拆分
把一个主 账户拆分成数个子账户，然后把请求分配到各个子账户上，这样单个账户的压力就小了。然后再用其他手段把子账户的数据合并成主账户数据，返回给用户。

汇总明细记帐
实时的交易全部是insert账务明细(insert 的开销很小，能够支持高并发。如果基于分布式部署,insert的并发容量理论上可以无限大) ,然后定时( 比如每半个小时)将之前半个小时内的账务明细sum出一个结算总金额，一笔入账结算到指定账户。
这个方案的缺点就是:交易不能实时入账，其实如果控制好定时汇总入账的频度,比如分钟级，用户也是可以接受的。这种方式对收单类业务( 账户加钱)非常实用，但是对支出类业务( 账户减钱)类来说，有账户透支地风险。


缓冲记帐
将实时同步的记账请求进行异步化，以达到记账实时性和系统稳定性之间平衡的记账手段,这就是”削峰填谷“。
方案不足:
热点账户在某几个高峰时间点需要缓冲记账来削峰填谷，并且能在日间填完。一旦账户的日间交易量暴增，导致日间队列根本来不及消化，整个队列越来越长,那就不存在谷可以填,这时候肯定会带来用户大量的投诉。另外这种方案对支出类业务(账户减钱)来讲，也会有账户透支地风险。

<<深入分布式缓存>>