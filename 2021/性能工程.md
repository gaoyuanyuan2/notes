# 性能工程

性能工程师对待计算机和互联网的性能问题也是如此，会观察各种参数，甚至进行主动的性能测试。根据各种参数和性能测试的结果，可以做出分析，并最终确定性能问题的根因。这之后进行性能优化来消除对应的性能问题。

## 代码性能和系统容量效率

代码性能表现在很多方面和指标，比较常见的几个指标有吞吐量(Throughput) 、服务延迟(Service latency) 、扩展性(Scalability) 和资源使用效率(Resource Utilization)
* 吞吐量:单位时间处理请求的数量。
* 服务延迟:客户请求的处理时间。
* 扩展性:系统在高压的情况下能不能正常处理请求。
* 资源使用效率:单位请求处理所需要的资源量(比如CPU,内存等)

计算机通常都会有数量不大的缓存。数组在内存里是连续存放的,所以,如果访问数组元素的时候能够按照顺序来,缓存可以起到极大的加速作用。

服务器的逻辑CPU不是物理CPU。在超线程技术(Hyper Threading)的情况下，服务器的吞吐不是严格按照逻辑CPU的使用率来提升的,因为两个逻辑CPU实共享很多物理资源。
在一台有8个逻辑CPU的服务器上，如果部署超过4个线程,得到的性能提升非常有限，甚至可能会带来其他不好的后果。这里具体的提升率和效果，取决于线程和应用程序的特性。

### 系统

我们每个人负责的代码模块，-般都不是孤立存在的，都要和其他模块交互。模块之间是唇齿相依的。如果一个模块性能不好，- 定会在某种情况下影响到其他模块,甚至是整个程序的性能和服务质量。唇亡齿寒的道理我们都懂,所以每个软件模块的性能都需要严格把关。

指数退避机制(Exponential Backoff )，通过快速地降低请求速度来帮助下游模块恢复(上游模块对下游资源进行重试请求的时间间隔，要随着失败次数的增加而指数加长)。

一个高性能的服务,在服务同等数量的客户时，需要的成本会比较小。具体来说，如果我们的服务是计算密集型，那么就应该尽量优化算法和数据结构等方面来降低CPU的使用量，这样就可以用尽量少的服务器来完成同样的需求，从而降低公司的成本。

### 需要哪些知识？

第一个特点是知识面要广，并且软硬结合。

第二个特点是"理论联系实际”。

第三个特点是不但要会性能测试，还要会性能分析和性能优化。

写得了代码，查得出异常;理得清问题，做得了测量;找得到病根，开得出药方。


软件方面，实内容很多。图里面仅仅表示了几个方面，你可以参照我们上学时开的各种计算机方面的课程，尤其是操作系统、数据结构和算法、编译原理以及各类协议。这方他包括很多数学和统计方面的知识。
硬件方面包括服务器本身、存储系统、各类网络、数据中心等等。这方面的重点是服务器本身的部件，比如CPU、内存等等。
实践经验，主要是关于性能方面的。比如很多系统的命令来观察系统资源的使用率,各种调试和测试工具，以及如何进行性能分析和性能优化的实践。
软技能方面， 做性能优化和容量管理工作经常需要和其他的团队和人员打交道。这些团队包括开发团队、数据中心团队、运维团队等等，需要和他们紧密而愉快地合作。同时，性能分析和优化经常需要把数据和分析展示给别人和领导看，这就需要你拥有一定的演讲能力。


性能工程师对待计算机和互联网的性能问题也是如此，会首先观察各种参数，至进行主动的场景测试。根据性能测试的结果，可以做出分析,并最终确定性能问题的根因。这之后可以进行相应的性能优化来消除对应的性能问题。采取优化后，还需要进行重新测试来确定问题真正得到解决,亦或是另有他因,从而需要重新分析。

## 性能定律和数理基础

### 性能工程三定律

### 概率统计和排队论

### 性能数据分析

CPU的便用上，网端上，还是存储的IO读写上

### 性能数据的展示

### 必须熟记的一组常用性能数字

一秒钟是1000毫秒(ms)，-秒是1000微秒(us)，一微秒是1000纳秒(ns)。

对所有的存储来说，有三个基本的性能指标。
1. IO读写延迟。一般是用4KB大小的IO做基准来测试;
2. IO带宽，一般是针对比较大的IO而言;
3. IOPS,就是每秒钟可以读写多少个小的随机IO。

下面这个表格列出了几种存储介质和它们的性能数值。

|存储种类|随机4KB-IO延迟|IO带宽|随机IOPS|
|:-:|:-:|:-:|:-:|
|传统硬盘(HDD)|8 ms|150 MB/s |120|
|SSD (SATA)|100 us|500 MB/s|30K|
|SSD (NVMe)|20 us|4 GB/s|400K|


#### CPU和内存相关

CPU运行程序时,最基本的执行单位是指令。而酶-条指令的执行都需要经过四步: 指令获取、指令解码、指令执行、数据存入。这些操作都是按照CPU周期来进行的，一般需要好几个周期。

我用下面的表格来表示一款2GHz主频的CPU,进行寄存器和缓存访问的一般延迟，分别用时钟周期数和绝对时间来表示，同时也给出在每个CPU核上面的字节大小。数字仅供参考，因为每款CPU都不同。

|缓存层级|访问时间(时钟周期)|访问时间 (纳米，ns)|大小 (Byte,每核)|
|:-:|:-:|:-:|:-:|
|寄存器|1|0.5 ns|8 Byte per寄存器|
|L1|4|2 ns|64 KB|
|L2|12|6 ns|256 KB|
|L3 (LLC)|50|20 ns|2 MB|
|DRAM内存(本地)|200|100 ns|2 GB|
|DRAM内存(远端)|400|200 ns|2 GB|

1.指令分支延迟
延迟一般在10纳秒左右。

2.互斥加锁和解锁
每个操作一般需要几十个时钟周期，10纳秒以上。

3.上下文切换
上下文切换可能需要几千个时钟周期，1微秒(1us) 级别。


网络的传输延迟是和地理距离相关的。网络信号传递速度不可能超过光速，一般光纤中速度是每毫秒200公左右。如果考虑往返时间(RTT, Round Trip Time)，那么可以大致说每100公里就需要一毫秒。 

在数据中心里面，一般的传输RT不超过半毫秒。如果是同一个机柜里面的两台主机之间,那么延迟就更小了，小于0.1毫秒。

如果光纤网络绕路的话，那么实际的RTT会超过以上估算数值。

传输延迟也取决于传输数据的大小，因为各种网络协议都是按照数据包来传输的，包的大小会有影响。比如一个20KB大小的数据,用1Gbps的网络传输，仅仅网卡发送延迟就是0.2秒。

|端到端环境|距离|RTT|
|:-:|:-:|:-:|
|机柜内部 |2米以内|< 0.1 ms|
|数据中心内部|100米以内|< 0.5 ms|
|北京→深圳| 2000公里|20 ms|
|上海→乌鲁木齐|4000公里|40 ms|
|中国→美国|10000公里|100 ms|











