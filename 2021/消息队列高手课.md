# 消息队列高手课

* 熟练使用各种常用集合，比如：数组、链表、字典等；
* 掌握 Linux 系统的基础知识，会使用常用的命令；
* 具备多线程、并发控制编程能力；
* 编写过读写文件、通过网络收发数据的程序；
* 能看懂最基本的 UML 图，包括类图、时序图等；
* 了解最常用的几种设计模式和算法。

对于实现消息队列中涉及的重要的实现技术，像网络通信、序列化反序列化、分布式事务、内存管理等，这部分内容是这门课程中的精粹，需要你重点学习。

RocketMQ 官方文档： https://rocketmq.apache.org/docs/quick-start/

RocketMQ 中国开发者中心：http://rocketmq.cloud/zh-cn/ 

Kafka 官方文档： http://kafka.apache.org/documentation/

RabbitMQ 官方文档： https://www.rabbitmq.com/documentation.html

在使用消息队列的过程中，如果遇到问题，要善用搜索引擎，我推荐你首选 Google，次之是 Stack Overflow，相对而言，这些搜索引擎搜索到有价值信息的概率会更高一些。
Stack Overflow：https://stackoverflow.com/


## 为什么需要消息队列？

消息队列最常被使用的三种场景：异步处理、流量控制和服务解耦。当然，消息队列的适用范围不仅仅局限于这些场景，还有包括：
作为发布 / 订阅系统实现一个微服务级系统间的观察者模式；
连接流计算任务和数据；
用于将消息广播给大量接收者。
简单的说，我们在单体应用里面需要用队列解决的问题，在分布式系统中大多都可以用消息队列来解决。

同时我们也要认识到，消息队列也有它自身的一些问题和局限性，包括：
引入消息队列带来的延迟问题；
增加了系统的复杂度；
可能产生数据不一致的问题。


首先redis肯定是不适合存消息的，虽然redis性能很好，但那是和主流的数据库比，一般大概能到几万tps左右；而现代的消息队列都能很轻松的做到几十万tps级别的性能。

消息量特别大的时候，需要考虑使用有消息堆积能力的MQ，因为一旦消费慢，大量消息就会堆积到MQ中，这种情况不太适合用RabbitMQ，可以考虑RocketMQ、Kafka和Pulsar。

令牌桶
如果计数是业务需求必须要求准确，简单一点的话，可以使用Redis的INCR命令来计数，这个是可以保证原子性的。Redis性能要是不能满足要求，也可以用Kafka+flink集群来解决。这两种方案都是可以保证完全准确计数的。

1.数据同步：包括业务服务之间的业务数据同步（主要是状态）、DB间的数据同步等等
2.异步通知：包括发送IM消息、异步日志、异步短信/邮件（尤其是批量数据）或注册/开启任务等等
3.信息收集：主要用于数据统计、监控、搜索引擎等等
4.服务解耦：主要用于重构和新设计时，对频繁变动的接口服务进行解耦（通常是被需求给逼的）
5.分布式事务消息：尤其是对数据一致性有要求的异步处理场景
6.主动性防御：秒杀、限流


涉及到钱的系统，数据可靠性是最先需要考虑的问题。

很多公司会用消息队列来做异构数据库之间的数据同步，但是一定要注意顺序问题。像MySQL Binlog这种，是要求严格有序的，否则会出现问题。



异地容灾是个比较难解决的问题。

我的经验是：绝大部分主题是不需要异地容灾的，因为消息队列不会直接对外提供服务，它直接服务都是机房内部的应用，当出现整个机房大面积断电或者机房外网中断的时候，消息的生产者本身已经不能提供服务了，这时候消息队列的容灾是没有意义的。如果生产者它本身支持异地容灾能自动把服务迁移到其它机房，那这个应用在其它机房的实例使用本机房内的消息队列就行了，也不需要消息队列做异地复制和容灾。

但是，确实有极少数应用比较特殊，它是有异地容灾的需求的，我们目前的方案是多副本分布在多个机房中，配合就近消费来实现。

这个超时异常有哪些场景会发生？

首先需要检查一下本机的是不是负载太高，是不是有fullGC，这些都会拖慢程序整体运行。如果是发消息超时，需要联系运维人员，如果是收消息超时，优先看一下消费的业务逻辑是不是执行的太慢了。

高频访问没有限制住，还是错误的限制了正常的访问？
建议采用的原则是“宁可暂时放过几个坏人，也不要错杀一个好人”，因为精确的做访问限制需要付出的性能代价是比较大的，一般可以采用不那么精确的方法。比如，你可以异步在Redis里面给每个session访问次数计数，每隔一段时间统计一下哪些session超频，定时（比如每分钟）更新这个超频session的黑名单，来请求的时候直接查黑名单来决定是否放行。这样可能没有实时统计，实时计算来得精确，但性能损失比较小，也可以达到限制超频访问的目的。

## 该如何选择消息队列？

作为一款及格的消息队列产品，必须具备的几个特性包括：
* 消息的可靠传递：确保不丢消息；
* Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
* 性能：具备足够好的性能，能满足绝大多数场景的性能要求。

RabbitMQ 就像它的名字中的兔子一样：轻量级、迅捷，它的 Slogan，也就是宣传口号，也很明确地表明了 RabbitMQ 的特点：Messaging that just works，“开箱即用的消息队列”。也就是说，RabbitMQ 是一个相当轻量级的消息队列，非常容易部署和使用。

### RabbitMQ

RabbitMQ 就像它的名字中的兔子一样：轻量级、迅捷，它的 Slogan，也就是宣传口号，也很明确地表明了 RabbitMQ 的特点：Messaging that just works，“开箱即用的消息队列”。也就是说，RabbitMQ 是一个相当轻量级的消息队列，非常容易部署和使用。


接下来说下 RabbitMQ 的几个问题。

第一个问题是，RabbitMQ 对消息堆积的支持并不好，在它的设计理念里面，消息队列是一个管道，大量的消息积压是一种不正常的情况，应当尽量去避免。当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。

第二个问题是，RabbitMQ 的性能是我们介绍的这几个消息队列中最差的，根据官方给出的测试数据综合我们日常使用的经验，依据硬件配置的不同，它大概每秒钟可以处理几万到十几万条消息。其实，这个性能也足够支撑绝大多数的应用场景了，不过，如果你的应用对消息队列的性能要求非常高，那不要选择 RabbitMQ。

最后一个问题是 RabbitMQ 使用的编程语言 Erlang，这个编程语言不仅是非常小众的语言，更麻烦的是，这个语言的学习曲线非常陡峭。大多数流行的编程语言，比如 Java、C/C++、Python 和 JavaScript，虽然语法、特性有很多的不同，但它们基本的体系结构都是一样的，你只精通一种语言，也很容易学习其他的语言，短时间内即使做不到精通，但至少能达到“会用”的水平。

### RocketMQ 

阿里巴巴在 2012 年开源的消息队列产品

RocketMQ 对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。

RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息。

RocketMQ 的一个劣势是，作为国产的消息队列，相比国外的比较流行的同类产品，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹。

### Kafka

当下的 Kafka 已经发展为一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性等方面都可以满足绝大多数场景的需求。

Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka。

Kafka 使用 Scala 和 Java 语言开发，设计上大量使用了批量和异步的思想，这种设计使得 Kafka 能做到超高的性能。Kafka 的性能，尤其是异步收发的性能，是三者中最好的，但与 RocketMQ 并没有量级上的差异，大约每秒钟可以处理几十万条消息。

使用配置比较好的服务器对 Kafka 进行过压测，在有足够的客户端并发进行异步批量发送，并且开启压缩的情况下，Kafka 的极限处理能力可以超过每秒 2000 万条消息。

但是 Kafka 这种异步批量的设计带来的问题是，它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。



### 选型

如果说，消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品，我建议你使用 RabbitMQ。

如果你的系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，那 RocketMQ 的低延迟和金融级的稳定性是你需要的。

如果你需要处理海量的消息，像收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品，那 Kafka 是最适合你的消息队列。

## 消息模型：主题和队列有什么区别？

在发布 - 订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

这个确认机制很好地保证了消息传递过程中的可靠性，但是，引入这个机制在消费端带来了一个不小的问题。什么问题呢？为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则。

### RabbitMQ

在 RabbitMQ 中，Exchange 位于生产者和队列之间，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange，由 Exchange 上配置的策略来决定将消息投递到哪些队列中。

同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相地实现新发布 - 订阅模型中，“一份消息数据可以被多个订阅者来多次消费”这样的功能。


### RocketMQ

每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。需要注意的是，RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。

在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的。

消费者组和队列数没有关系，你这个例子中消费者组的数量是2个。队列数量可以根据数据量和消费速度来合理配置。RocketMQ和Kafka都可以支持水平扩容队列数量，但是都需要手动操作。

producer会往所有队列发消息，但不是“同一条消息每个队列都发一次”，每条消息只会往某个队列里面发送一次。

对于一个消费组，每个队列上只能串行消费，多个队列加一起就是并行消费了，并行度就是队列数量，队列数量越多并行度越大，所以水平扩展可以提升消费性能。

每队列每消费组维护一个消费位置（offset），记录这个消费组在这个队列上消费到哪儿了。



1、主题（topic）中有多个队列（队列数量可以水平进行扩容），生产者将其消息发送给主题中的某个队列（根据一定的路由规则，比如取模之类的），主题不保证消息的有序，只有队列中的消息才是有序的。
2、从主题中的所有队列中取出消息给所有消费组进行消费，消息只能被消费组中的一个线程进行消费，有点类似线程池的形式，工作线程消费来自不同队列的消息，感觉这也是RocketMq,低时延的原因，不同队列中的消息可以同时被消费，并且消费组的线程也可以并发的消费不同的消息。
3、由于主题中的一个队列都会被多个消费组进行消费，为此需要为每个消费组的消费的不同队列为此一个下标(每个消费组可以一直消费队列中的消息，无需等待其他消费组的确认)，主题中的队列消息是有序的，为此需要等到所有消费组对此条消息进行确认，才能从队列中移除，感觉每个消费组的队列下标，可以一个队列维护一个CurrentHashMap来为此每个消费组的下标，这样的话可以防止锁的竞争。
队列可以维护一个全局的下标，消费队列时，使用CAS进行下标的获取，由于不保证消息消费的有序，这样的话可以并发的消费消息，由于有全局下标，不会出现获取队列的空洞消息。

* rocketmq，一个消费组在一个主题下的多个队列并发消费就无法保证消息的顺序性。这种该如何处理?
按照订单ID或者用户ID，用一致性哈希算法，计算出队列ID，指定队列ID发送，这样可以保证相同的订单/用户的消息总被发送到同一个队列上，就可以确保严格顺序了。
* 客户端和mq要保持一种重试的机制，如果在网络延迟出现问题的时候，前面的消息一直未收到ack响应，若不做任何处理，后面的就会阻塞，还是重试之后放弃，若是不能发生丢失的信息该如何处理。
会有一个超时，超时之前会阻塞，超时之后就解除锁定，允许其他消费者来拉消息，由于消费位置没变，下次再有消费者来这个队列拉消息，返回的还是上一条消息。

正常情况下，所有消费组的消费速度都应该和生产速度差不多。

实际上并不是一条一条确认的，而是一批一批确认的。一般consumer取一批消息，然后确认的时候直接提交这批消息中最后一条消息的位置来确认这批消息。

producer和queue不需要关联，简单点儿说，就是发到哪个queue都可以。RocketMQ的默认策略是轮询选择每个queue。

消费组中某个消费者在消费一个队列的时候，其他同组的消费者是不能消费这个队列的，但是他们可以去消费同主题的其它队列，所以并不是空闲的。并且，即使是这些消费者并行消费不同的队列，在每个队列上，还是可以保证严格顺序的。

消费端拉10条数据后，消费位置不变，之后10条全消费成功了，offset才加10。

多个消费组的目的就是每个消费组都要消费主题上一份完整的消息。如果你只是希望消息只消费一次，你应该只使用一个消费组，组内可以配置多个消费者来达到并行消费的目的。

### Kafka

所有 RocketMQ 中对应的概念，和生产消费过程中的确认机制，都完全适用于 Kafka。唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别的。


Kafka和RocketMQ的消费模型是一样的。有一个小的区别是，Kafka把Consumer绑定到Patition上，如果Consumer数量或者分区数量变化，需要reblance，而RocketMQ它不绑定Consumer和Queue，而采用的是分时占用策略，只要Queue没有Consumer在占用，任何一个Consumer都可以来消费。

## 如何利用事务消息实现分布式事务？

这个过程中有一个需要用到消息队列的步骤，订单系统创建订单后，发消息给购物车系统，将已下单的商品从购物车中删除。因为从购物车删除已下单商品这个步骤，并不是用户下单支付这个主要流程中必需的步骤，使用消息队列来异步清理购物车是更加合理的设计。

问题的关键点集中在订单系统，创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败，不允许一个成功而另一个失败的情况出现。

比较常见的分布式事务实现有 2PC（Two-phase Commit，也叫二阶段提交）、TCC(Try-Confirm-Cancel) 和事务消息。

### 消息事务

消息队列上开启一个事务，然后订单系统给消息服务器发送一个“半消息”，这个半消息不是说消息内容不完整，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

半消息发送成功后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果决定提交或者回滚事务消息。如果订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息继续后续的流程。如果订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。这样就基本实现了“要么都成功，要么都失败”的一致性要求。

如果在第四步提交事务消息时失败了怎么办？对于这个问题，Kafka 和 RocketMQ 给出了 2 种不同的解决方案。

Kafka 的解决方案比较简单粗暴，直接抛出异常，让用户自行处理。我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿。RocketMQ 则给出了另外一种解决方案。

RocketMQ 中的分布式事务实现

在 RocketMQ 中的事务实现中，增加了事务反查的机制来解决事务消息提交失败的问题。如果 Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。
为了支撑这个事务反查机制，我们的业务代码需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败。

A:本地事物的操作1，与往消息队列中生产消息的操作2，是两个分离的操作，不符合对原子性的定义；
C:由于操作消息队列属于异步操作，在数据一致性上，只能保证数据的最终一致性。若对于时效性要求很高的系统来说，事物消息不是数据一致的；但对于时效性要求不高的系统来说，他就是数据一致的。我认为，用不同的业务视角来看问题，会有不同的答案；
I：隔离性上，由于事物消息是分两步操作的，本地事物提交后，别的事物消息就已经可以看到提交的消息了。所以，不符合隔离性的定义；
D：持久性上，rocketMq上支持事物的反查机制，但我不太清楚“半消息”是存储在磁盘中，还是内存里。若存储在磁盘中，那就支持持久性，即使事物消息提交后，发生服务突然宕机也不受影响；若存储在内存中，则无法保证持久性。

实现订单下单场景：
1. 首先通过producer.sendMessageInTransaction()方法发送一个半消息给MQ.
2. 此时会在TransactionListener中的executeLocalTransaction()方法阻塞，然后在这个方法里面进行订单创建并提交本地事务，如果commit成功，则返回COMMIT状态，否则是ROLLBACK状态，如果正常返回COMMIT或者ROLLBACK的话，不会存在第3步的反查情况。
3. 如果上面的本地事务提交成功以后，此节点突然断电，那么checkLocalTransaction()反查方法就会在某个时候被MQ调用，此方法会根据消息中的订单号去数据库确认订单是否存在，存在就返回COMMIT状态，否则是ROLLBACK状态。
4. 购物车在另外一个项目中，反正只要收到MQ的消息就将本次订单的商品从购物车中删除即可。

RocketMQ给出的解决方案是，反查的结果返回的状态中，不仅有成功和失败，还有一个“不确定”的状态，意思就是“我现在不知道本地事务是不是成功了，将来它可能会成功，也可能会失败”，像你提的这两种情况，在实现反查接口的时候，都应该返回不确定的状态，RocketMQ在收到这个状态后，会定时多次进行反查，直到得到成功、失败的状态或者事务超时才结束。

对于你说的“坏消息”（消费端抛出异常），反复消费都不能成功，有的MQ会把这种消息放到一个单独的特殊队列中，等着后续人工处理，避免卡死队列。


如果有一个生产者和消费者都可以访问的，并且性能还不错数据库，肯定是使用这个数据库来实现事务比较好。

大部分事务消息使用的场景是，没有这样的数据库的。或者由于设计、安全或者网络原因，生产者消费者不能共享数据库，或者是数据库的性能达不到要求。


一般MQ的Broker都有高可用方案，不会出现一个节点宕机就无法发消息的问题。所以不用担心这个问题。




