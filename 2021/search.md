# 检索核心技术

## 检索技术分为了四个层级

第一层是存储介质层。因为检索效率的高低和数据存储的方式是紧密联系的，所以，存储介质的特性是我们需要学习的基础知识。

第二层是数据结构与算法层。提到”效率”，自然就离不开数据结构和算法。

第三层是检索专业知识层。如果我们想实现工业界中的检索引擎，需要掌握这些检索技术。我把它们划分为两部分，分别是工程架构和算法策略。

第四层是检索技术的应用层。检索技术在互联网中有许多应用场景，其中最常见的，有搜索引擎、广告引擎、以及推荐引擎。这些业务系统有相似的工程架构和算法部分，也分别有自己独特的业务处理环节。


为了追求更高的检索性能，我们一般不会直接对索引加锁，而是会利用“双buffer机制”来实现索引更新。但是像搜索引擎这样万亿级网页的索引|规模，无法直接使用“双buffer机制"来更新，需要使用“全量索引结合增量索引”方案来更新索引。


## 数据结构

* 数据库的检索技术B+树
* NoSQL中的LSM树

AVL 树（平衡二叉树）和红黑树，其实它们本质上都是二叉检索树，但它们都在保证左右子树差距不要太大上做了特殊的处理，保证了检索效率，让二叉检索树可以被广泛地使用。

我们可以为链表的某些节点增加更多的指针。这些指针都指向不同距离的后续节点。这样一来，链表就具备了更高效的检索能力。这样的数据结构就是跳表（Skip List）
在 Redis 这样的系统中，我们经常会利用跳表来代替红黑树作为底层的数据结构。

### 哈希冲突

对于哈希冲突这个问题，我们有两类解决方案: 
一类是构造尽可能理想的 Hash 函数，使得 Hash 以后得到的数值尽可能平均分布，从而减少冲突发生的概率；
另一类是在冲突发生以后，通过“提供冲突解决方案”来完成存储和查找。
最常用的两种冲突解决方案是“开放寻址法”和“链表法”。

如何利用开放寻址法解决 Hash 冲突？
所谓“开放寻址法”，就是在冲突发生以后，最新的元素需要寻找新空闲的数组位置完成插入。那我们该如何寻找新空闲的位置呢？我们可以使用一种叫作“线性探查”（Linear Probing）的方案来进行查找。
“线性探查”的插入逻辑很简单：在当前位置发现有冲突以后，就顺序去查看数组的下一个位置，看看是否空闲。如果有空闲，就插入；如果不是空闲，再顺序去看下一个位置，直到找到空闲位置插入为止。

如果哈希表已经比较满了，这个 Key 就会沿着数组一直顺序遍历，直到遇到空位置才会成功插入。查询的时候也一样。但是，顺序遍历的代价是 O(n)，这样的检索性能很差。

为了解决这个问题，我们可以使用“二次探查”（Quadratic Probing）和“双散列”（Double Hash）这两个方法进行优化。下面，我来分别解释一下这两个方法的优化原理。

二次探查就是将线性探查的步长从 i 改为 i^2：第一次探查，位置为 Hash(key) + 1^2；第二次探查，位置为 Hash(key) +2^2；第三次探查，位置为 Hash(key) + 3^2，依此类推。

双散列就是使用多个 Hash 函数来求下标位置，当第一个 Hash 函数求出来的位置冲突时，启用第二个 Hash 函数，算出第二次探查的位置；如果还冲突，则启用第三个 Hash 函数，算出第三次探查的位置，依此类推。

链表法：就是将我们前面讲过的数组和链表进行结合，既利用了数组的随机访问特性，又利用了链表的动态修改特性，同时提供了快速查询和动态修改的能力。

为了保证哈希表的检索效率，我们需要预估哈希表中的数据量，提前生成足够大的哈希表。按经验来说，我们一般要预留一半以上的空闲位置，哈希表才会有足够优秀的检索效率。这就让哈希表和有序数组、二叉检索树相比，需要的存储空间更多了。

链表法可以直接删除，开放寻址法不行。
不能直接删除的问题在于，直接删除会把探查序列中断。举个例子:有三个元素a，b，c的hash值是冲突的，那么探查序列会把他们放在三个位置上，比如1，2，3（探查序列是123），如果我们把b删了，那么2这个位置就空了。这时候，要查询c，探查序列就会在2的位置中断，查不到c。

### 如何使用位图来减少存储空间？

使用 char 类型的数组，依然是一个非常“浪费空间”的方案。因为表示 0 或者 1，
理论上只需要一个 bit。所以，如果我们能以 bit 为单位来构建这个数组，那使用空间就是int 32 数组的 1/32，从而大幅减少了存储使用的内存空间。这种以 bit 为单位构建数组的方案，就叫作 Bitmap，翻译为位图。
位图的优势非常明显，但许多系统中并没有以 bit 为单位的数据类型。因此，我们往往需要对其他类型的数组进行一些转换设计，使其能对相应的 bit 位的位置进行访问，从而实现位图。

## 倒排索引

如何创建倒排索索引？

1. 给每个文档编号，作为其唯一的标识，并且排好序，然后开始遍历文档（为什么要先排序，然后再遍历文档呢？你可以先想一下，后面我们会解释）。
2. 解析当前文档中的每个关键字，生成 < 关键字，文档 ID，关键字位置 > 这样的数据对。为什么要记录关键字位置这个信息呢？因为在许多检索场景中，都需要显示关键字前后的内容，比如，在组合查询时，我们要判断多个关键字之间是否足够近。所以我们需要记录位置信息，以方便提取相应关键字的位置。
3. 将关键字作为 key 插入哈希表。如果哈希表中已经有这个 key 了，我们就在对应的 posting list 后面追加节点，记录该文档 ID（关键字的位置信息如果需要，也可以一并记录在节点中）；如果哈希表中还没有这个 key，我们就直接插入该 key，并创建posting list 和对应节点。
4. 重复第 2 步和第 3 步，处理完所有文档，完成倒排索引的创建


如果倒排索引非常大，内存不可能全部载入所有索引?
内存放不下，有三个思路:
1.通过压缩，全塞进内存；
2.放磁盘上，用b+树或分层跳表处理；
3.分布式，分片后全放内存。
